{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Loading and concatenating time series\n",
    "----------------------\n",
    "\n",
    "The length is $N$ was equal to 100620 as a result of concatenating timeseries of length 53040 for dual n-back task and 47580 for rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of concatenated timeseries: (100620, 400)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Loading concatenated timeseries\n",
    "data = np.load(\"./data/neuroimaging/concat_timeseries_shaefer400_pipeline-24HMP_8Phys_SpikeReg_4GS.npy\", allow_pickle=True).item()\n",
    "\n",
    "# Concatenating dualnback and rest\n",
    "concat_ts_dualnback = data['tasks']['dualnback']['timeseries']\n",
    "concat_ts_rest = data['tasks']['rest']['timeseries']\n",
    "\n",
    "len_dualnback = concat_ts_dualnback.shape[0]\n",
    "len_rest = concat_ts_rest.shape[0]\n",
    "\n",
    "n_rois = data['tasks']['dualnback']['timeseries'].shape[1]\n",
    "\n",
    "X = np.zeros((len_dualnback + len_rest, n_rois))\n",
    "X[:len_dualnback,:] = concat_ts_dualnback \n",
    "X[len_dualnback:, :] = concat_ts_rest\n",
    "\n",
    "print(f\"Shape of concatenated timeseries: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Clustering the timeseries into brain states\n",
    "----------------------\n",
    "\n",
    "To discover main brain states existing in time-series we performed 100 repetitions of $k$-means clustering from $k$ = 2 to $k$ = 18 using Euclidean distance as a measure of similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist,pdist\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Setup\n",
    "k_min = 2\n",
    "k_max = 18\n",
    "n_jobs = 8\n",
    "n_init = 100\n",
    "K = range(k_min, k_max+1)\n",
    "\n",
    "# K-means clustering\n",
    "kmeans_model = [KMeans(n_clusters=k, n_init=n_init, random_state=1234, n_jobs=n_jobs).fit(X) for k in K]\n",
    "\n",
    "# Getting additional K-means quality measures\n",
    "total_wss = np.array([cent.inertia_ for cent in kmeans_model]) # Total within-cluster sum of squares\n",
    "total_ss = sum(pdist(X)**2)/X.shape[0]     # Total sum of squares\n",
    "between_ss = total_ss - total_wss          # Between-cluster sum of squares\n",
    "\n",
    "# Silhouette score\n",
    "silhouette = np.array([silhouette_score(X, lab.labels_, metric='euclidean', sample_size=10) for lab in kmeans_model])\n",
    "\n",
    "# Saving dictionary with all metadata\n",
    "kmeans_output = data.copy()\n",
    "kmeans_output['kmeans'] = {'kmeans_models': kmeans_model, \n",
    "                           'total_wss': total_wss, \n",
    "                           'total_ss': total_ss,\n",
    "                           'between_ss': between_ss,\n",
    "                           'variance_explained': between_ss/total_ss*100,\n",
    "                           'silhouette': silhouette,\n",
    "                           'k_range': K,\n",
    "                           'n_init': n_init}\n",
    "\n",
    "kmeans_output['tasks']['dualnback']['len'] = len_dualnback                                                \n",
    "kmeans_output['tasks']['rest']['len'] = len_rest\n",
    "kmeans_output['tasks']['dual_rest'] = {'timeseries': X,\n",
    "                                       'denoising': np.unique([kmeans_output['tasks']['dualnback']['denoising'], \n",
    "                                                               kmeans_output['tasks']['rest']['denoising']]),\n",
    "                                       'len': len_dualnback + len_rest\n",
    "                                      }                                  \n",
    "kmeans_output['tasks']['dualnback']['timeseries'] = None\n",
    "kmeans_output['tasks']['rest']['timeseries'] = None\n",
    "\n",
    "filename = 'kmeans_' + data['filename']\n",
    "kmeans_output['filename'] = filename\n",
    "\n",
    "np.save(f\"./data/neuroimaging/{filename}.npy\", kmeans_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

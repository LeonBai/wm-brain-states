{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brain states transitions in response to working memory training\n",
    "=================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyses performed by Karolina Finc & Justyna Kuk, \n",
    "*Centre for Modern interdisciplinary Technologies, Nicolaus Copernicus University in Toru≈Ñ*\n",
    "\n",
    "Last edited: 08-07-2019\n",
    "\n",
    "--------------\n",
    "\n",
    "The goal of this analysis is to examine the effects of working memory training on *time-resolved brain state dynamics* examined in the trained task and the resting-state. Does working memory training affects brain state distribution in the task? \n",
    "\n",
    "We used unsupervised machine learning approach to cluster dual n-back and resting-state fMRI time-series into discrete brain states (see Chen et al., 2015; Cornblath et al., 2018). We hypothesize that:\n",
    "- The brain states fluctuation will differ after working memory training especially in the states related to default mode and frontoparietal systems activity. \n",
    "- Training-related changes in brain states dynamics will be more visible during the trained task than the resting state.\n",
    "- Individual characteristics of brain states fluctuations will be associated to individual behavioral differences in training progress.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Timeseries preparation\n",
    "----------\n",
    "\n",
    "Prior to running clustering the time-series into discrete brain stets, all timeseries were concatenated into large $N \\times P$ array containing $N$ observation and $P$ features. The length of $N$ was equal to 227040 as a result of concatenating 4 sessions of dual n-back data (340 time-points) and resting state data (305 time-points) of 44 subjects. The length of $P$ was equal 400 and represented the mean signal extracted from each brain areas of Schaefer et al. (2019) brain parcellation.\n",
    "\n",
    "By this procedure we ensured the correspondence of brain states labels across subjects, sessions and tasks.\n",
    "\n",
    "(for now, we just testing code on small subsample of dataset -- 8 subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dualnback data shape: (8, 4, 340, 400)\n",
      "Original dualnback data shape: (8, 4, 305, 400)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Loading time-series data\n",
    "ts_dualnback = np.load(\"timeseries_schaefer400_dualnback.npy\")\n",
    "ts_rest = np.load(\"timeseries_schaefer400_rest.npy\")\n",
    "\n",
    "n_sub = 8 # Select number of subjects \n",
    "ts_dualnback = ts_dualnback[:n_sub]\n",
    "ts_rest = ts_rest[:n_sub]\n",
    "\n",
    "print(f'Original dualnback data shape: {ts_dualnback.shape}')\n",
    "print(f'Original dualnback data shape: {ts_rest.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dualnback timeseries: (10880, 400)\n",
      "Shape of rest timeseries: (9760, 400)\n",
      "Shape of all timeseries: (20640, 400)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating time-series\n",
    "n_ses = ts_dualnback.shape[1]\n",
    "n_rois = ts_dualnback.shape[3]\n",
    "\n",
    "cts_dualnback = ts_dualnback.reshape(n_sub*n_ses*ts_dualnback.shape[2], n_rois)     #all 46 subcjects in one vector\n",
    "cts_rest = ts_rest.reshape(n_sub*n_ses*ts_rest.shape[2], n_rois)\n",
    "\n",
    "# Concatenating task and rest\n",
    "cts_all = np.zeros((cts_dualnback.shape[0] + cts_rest.shape[0] , n_rois))\n",
    "cts_all[0:cts_dualnback.shape[0],:] = cts_dualnback \n",
    "cts_all[cts_dualnback.shape[0]:, :] = cts_rest\n",
    "\n",
    "print(f'Shape of dualnback timeseries: {cts_dualnback.shape}')\n",
    "print(f'Shape of rest timeseries: {cts_rest.shape}')\n",
    "print(f'Shape of all timeseries: {cts_all.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Clustering the timeseries into brain states\n",
    "----------------------\n",
    "\n",
    "To discover main brain states existing in time-series we performed 500 repetitions of $k$-means clustering from $k$ = 2 to $k$ = 18 using Euclidean distance as a measure of similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering for k = 2\n",
      "Clustering for k = 3\n",
      "Clustering for k = 4\n",
      "Clustering for k = 5\n",
      "Clustering for k = 6\n",
      "Clustering for k = 7\n",
      "Clustering for k = 8\n",
      "Clustering for k = 9\n",
      "Clustering for k = 10\n",
      "Clustering for k = 11\n",
      "Clustering for k = 12\n",
      "Clustering for k = 13\n",
      "Clustering for k = 14\n",
      "Clustering for k = 15\n",
      "Clustering for k = 16\n",
      "Clustering for k = 17\n",
      "Clustering for k = 18\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "max_k = 18\n",
    "brain_states = np.zeros((max_k-1,cts_all.shape[0]))\n",
    "silhouette = np.zeros((max_k-1))\n",
    "\n",
    "for k in range(max_k-1):\n",
    "    print(f'Clustering for k = {k+2}')\n",
    "    kmeans = KMeans(n_clusters=k+2, n_init=10).fit(cts_all) # Change to 500 later\n",
    "    kmeans_predict = kmeans.fit_predict(cts_all)\n",
    "    brain_states[k,:] = kmeans.labels_\n",
    "    silhouette[k] = silhouette_score(cts_all, kmeans_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"brain_states.npy\", brain_states)\n",
    "np.save(\"silhouette_score.npy\", silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Selecting k size based on silhouette score and absent states\n",
    "-------------------------------------------------------------------------\n",
    "To identify the optimal number of clusters we use silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Plotting Silhouette score\n",
    "plt.plot(np.arange(2,19), silhouette)\n",
    "plt.grid()\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 20640)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 340, 8, 4)\n",
      "(17, 305, 8, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "brain_states = np.load('brain_states.npy')\n",
    "\n",
    "bs_dualnback = brain_states[:, :cts_dualnback.shape[0]]\n",
    "bs_rest = brain_states[:, cts_dualnback.shape[0]:]\n",
    "\n",
    "sub_ses_bs_dualnback = bs_dualnback.reshape(brain_states.shape[0], ts_dualnback.shape[2], n_sub, n_ses)\n",
    "sub_ses_bs_rest = bs_rest.reshape(brain_states.shape[0], ts_rest.shape[2], n_sub, n_ses)\n",
    "\n",
    "print(sub_ses_bs_dualnback.shape)\n",
    "print(sub_ses_bs_rest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "      <th>k</th>\n",
       "      <th>absent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject session  k  absent\n",
       "0  sub-01   ses-1  2       0\n",
       "0  sub-01   ses-1  3       0\n",
       "0  sub-01   ses-1  4       0\n",
       "0  sub-01   ses-1  5       0\n",
       "0  sub-01   ses-1  6       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functions import absent_states\n",
    "\n",
    "absent_states = absent_states(sub_ses_bs_dualnback)\n",
    "absent_states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Split-halves validation for k = 5\n",
    "-------------------------------------------------------------------------\n",
    "\n",
    "We also split our sample into two equal partitions 500 times and performed k-means clustering separately on each half of the dataset. We then matched clusters by computing the correlation between both sets of centroids, and then by reordering the clusters based on the maximum correlation value for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dim = int(t_vector.shape[0]/2)\n",
    "# train_series = np.zeros((500,dim,264))\n",
    "# test_series = np.zeros((500,dim,264))\n",
    "\n",
    "# for i in range(500):\n",
    "#     X_train, X_test = train_test_split(t_vector, test_size=0.5)\n",
    "#     train_series[i,:,:] = X_train\n",
    "#     test_series[i,:,:] = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# import pandas as pd\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# n_clusters = 6\n",
    "\n",
    "# cor = np.zeros((500,n_clusters,n_clusters))\n",
    "\n",
    "# for sub in range(500):\n",
    "#     train_kmeans = KMeans(n_clusters=n_clusters, n_init=500).fit(train_series[sub,:,:])\n",
    "#     test_kmeans = KMeans(n_clusters=n_clusters, n_init=500).fit(test_series[sub,:,:])\n",
    "#     x = train_kmeans.cluster_centers_\n",
    "#     y = test_kmeans.cluster_centers_\n",
    "#     for k in range(n_clusters):\n",
    "#         for j in range(n_clusters):\n",
    "#             cor[sub,k,j] = pearsonr(x[k],y[j])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cor_sort = np.sort(cor)\n",
    "# max_values = np.zeros((500,n_clusters))\n",
    "\n",
    "# for i in range(500):\n",
    "#     max_values = cor_sort[i,:,-1]\n",
    "#     mean_max_values = (cor_sort[i,:,-1]).mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nilearn import plotting\n",
    "\n",
    "# num = 0\n",
    "\n",
    "# print(cor_sort[num,:,-1])\n",
    "# plotting.plot_matrix(cor_sort[num,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Correlating cluster labels with well-known large-scale networks\n",
    "-------------------------------------------------------------------------\n",
    "\n",
    "To describe the pattern of brain dynamics characteristic for each brain state, we averaged timeseries across each cluster and calculated Pearson's correlation of resulting 400-element vector (mean activity within each parcel from Schaefer parcellation) with binary vectors representing *a priori* defined 7-network partition (Schaefer, et al. 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAABLCAYAAABEDTEaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAjxJREFUeJzt3DFq1EEYxuFvJIIJgiAKFkIsBBGCFlp5BT3HXkDIJYIXsBBPYWFprY1YxkoL0TQGKxHHxsbG7AbmnezmebrAFO9X/eC/kNZ7LwAY7cLsAQCcD4IDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEVsnPWitLapqUVW1s90e3N69NHzULO9/zl4w1t73K7MnDLV1a3Pva+8uz54w1JebP2ZPGGr786/ZE4b5Vl/ruB+3Zd62Vf61zf27O/31yzunHnbW3fj0e/aEoQ5fPZ49YairL57MnjDMxfZo9oShDp69mT1hqHtPj2ZPGGa/9utjP1wqOD6pARAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQITgABAhOABECA4AEYIDQETrvf//QWuLqlr8/XOvqj6MHjXRtao6mj1ikE2+rcp9685962u39359mYcnBuefx6297b0/PPWsM26T79vk26rct+7cdz74pAZAhOAAELFqcJ4PWXF2bPJ9m3xblfvWnfvOgZV+wwGA0/JJDYAIwQEgQnAAiBAcACIEB4CIPwm0V7vZEDelAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "from nilearn.plotting import plot_roi\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Getting a priori defined 7-network partition's label \n",
    "schaefer400 = datasets.fetch_atlas_schaefer_2018(n_rois=400, \n",
    "                                           yeo_networks=7, \n",
    "                                           resolution_mm=1,\n",
    "                                           data_dir=None, \n",
    "                                           base_url=None, \n",
    "                                           resume=True, \n",
    "                                           verbose=1)\n",
    "\n",
    "# Dictionary to create network's abbreviations\n",
    "schaefer_dict = {\n",
    "    \"Vis\": \"VIS\",\n",
    "    \"SomMot\": \"SOM\",\n",
    "    \"DorsAttn\": \"DAN\",\n",
    "    \"Sal\": \"SAL\",\n",
    "    \"Limbic\": \"LIM\",\n",
    "    \"Cont\": \"FPM\",\n",
    "    \"Default\": \"DMN\"\n",
    "}\n",
    "\n",
    "networks = [val for key, val in schaefer_dict.items() for roi in schaefer400['labels'] if key in roi.decode('UTF-8')]\n",
    "\n",
    "# Creating color palette for netorks\n",
    "schaefer_colors = {'CON':'#e8c830',\n",
    "                   'DA':'#00ab2e', \n",
    "                   'DM':'#dc6179', \n",
    "                   'LIM':'#eeffc5', \n",
    "                   'SAL':'#f300ff',\n",
    "                   'SOM':'#7e8dc1', \n",
    "                   'VIS':'#ac00ad',}\n",
    "\n",
    "network_pal = (sns.color_palette(schaefer_colors.values()))\n",
    "sns.palplot(network_pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_brain_states = brain_states[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 400)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating data frame with dummy codes for each brain state\n",
    "brain_states_filter = pd.get_dummies(k_brain_states)\n",
    "\n",
    "brain_states_filter = pd.DataFrame(brain_states_filter)\n",
    "brain_states_filter.columns = np.arange(1,6)\n",
    "\n",
    "# Getting mean brain states timeseries\n",
    "mean_brain_states = np.zeros((5,400))\n",
    "for i, col in enumerate(brain_states_filter):\n",
    "    state_filter = brain_states_filter[col].values.astype(bool)\n",
    "    mean_brain_states[i] = cts_all[state_filter].mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAN</th>\n",
       "      <th>DMN</th>\n",
       "      <th>FPM</th>\n",
       "      <th>LIM</th>\n",
       "      <th>SAL</th>\n",
       "      <th>SOM</th>\n",
       "      <th>VIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DAN  DMN  FPM  LIM  SAL  SOM  VIS\n",
       "0      0    0    0    0    0    0    1\n",
       "1      0    0    0    0    0    0    1\n",
       "2      0    0    0    0    0    0    1\n",
       "3      0    0    0    0    0    0    1\n",
       "4      0    0    0    0    0    0    1\n",
       "5      0    0    0    0    0    0    1\n",
       "6      0    0    0    0    0    0    1\n",
       "7      0    0    0    0    0    0    1\n",
       "8      0    0    0    0    0    0    1\n",
       "9      0    0    0    0    0    0    1\n",
       "10     0    0    0    0    0    0    1\n",
       "11     0    0    0    0    0    0    1\n",
       "12     0    0    0    0    0    0    1\n",
       "13     0    0    0    0    0    0    1\n",
       "14     0    0    0    0    0    0    1\n",
       "15     0    0    0    0    0    0    1\n",
       "16     0    0    0    0    0    0    1\n",
       "17     0    0    0    0    0    0    1\n",
       "18     0    0    0    0    0    0    1\n",
       "19     0    0    0    0    0    0    1\n",
       "20     0    0    0    0    0    0    1\n",
       "21     0    0    0    0    0    0    1\n",
       "22     0    0    0    0    0    0    1\n",
       "23     0    0    0    0    0    0    1\n",
       "24     0    0    0    0    0    0    1\n",
       "25     0    0    0    0    0    0    1\n",
       "26     0    0    0    0    0    0    1\n",
       "27     0    0    0    0    0    0    1\n",
       "28     0    0    0    0    0    0    1\n",
       "29     0    0    0    0    0    0    1\n",
       "..   ...  ...  ...  ...  ...  ...  ...\n",
       "370    0    1    0    0    0    0    0\n",
       "371    0    1    0    0    0    0    0\n",
       "372    0    1    0    0    0    0    0\n",
       "373    0    1    0    0    0    0    0\n",
       "374    0    1    0    0    0    0    0\n",
       "375    0    1    0    0    0    0    0\n",
       "376    0    1    0    0    0    0    0\n",
       "377    0    1    0    0    0    0    0\n",
       "378    0    1    0    0    0    0    0\n",
       "379    0    1    0    0    0    0    0\n",
       "380    0    1    0    0    0    0    0\n",
       "381    0    1    0    0    0    0    0\n",
       "382    0    1    0    0    0    0    0\n",
       "383    0    1    0    0    0    0    0\n",
       "384    0    1    0    0    0    0    0\n",
       "385    0    1    0    0    0    0    0\n",
       "386    0    1    0    0    0    0    0\n",
       "387    0    1    0    0    0    0    0\n",
       "388    0    1    0    0    0    0    0\n",
       "389    0    1    0    0    0    0    0\n",
       "390    0    1    0    0    0    0    0\n",
       "391    0    1    0    0    0    0    0\n",
       "392    0    1    0    0    0    0    0\n",
       "393    0    1    0    0    0    0    0\n",
       "394    0    1    0    0    0    0    0\n",
       "395    0    1    0    0    0    0    0\n",
       "396    0    1    0    0    0    0    0\n",
       "397    0    1    0    0    0    0    0\n",
       "398    0    1    0    0    0    0    0\n",
       "399    0    1    0    0    0    0    0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame with dummy codes for each network\n",
    "networks_binary = pd.get_dummies(networks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(n_clusters):\n",
    "    dum = pd.get_dummies(k_labels[0])\n",
    "    t_val = dum[i].values.astype(bool)\n",
    "    t_vec = t_vector[t_val,:]\n",
    "    vec_mean = t_vec.mean(axis=0) \n",
    "    mean_matrix[i,:] = vec_mean\n",
    "return(mean_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(t_vector, n_clusters):\n",
    "    '''\n",
    "    This function compare corralation between mean of the time-series for each cluster and modules.\n",
    "    Requires the k_time_series function and the module txt file.    \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    t_vector: array, vector of time_series\n",
    "    n_clusters: int, number of clusters\n",
    "    \n",
    "    \n",
    "    Return\n",
    "    -----------\n",
    "    Minimum and maximum Pearson correlation value fro each cluster,\n",
    "    plots for eaach cluster and module with Pearson correlation value.\n",
    "    '''\n",
    "    import numpy as np\n",
    "    \n",
    "    mean_matrix = k_time_series(n_clusters, t_vector)\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "\n",
    "    data = pd.read_csv('modules.txt', header=None)\n",
    "    values = np.zeros((len(np.unique(data)), 264))\n",
    "\n",
    "    for i in range(len(np.unique(data))):\n",
    "        dum = pd.get_dummies(data[0])\n",
    "        name = dum.keys()[i]\n",
    "        val = (dum[name])\n",
    "        values[i,:] = val\n",
    "    \n",
    "#Pearson correlation between time-series and modules:\n",
    "\n",
    "    from scipy.stats import pearsonr\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    w = np.zeros((n_clusters,13))       #13 different modules\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        c = -1 \n",
    "        d = 1\n",
    "        for j in range(values.shape[0]):\n",
    "            cor = pearsonr(mean_matrix[i][:], values[j][:])[0]\n",
    "            w[i,j] = cor\n",
    "            if cor>c:\n",
    "                c=cor\n",
    "                a=j\n",
    "            if cor<d:\n",
    "                d=cor\n",
    "                b=j\n",
    "        print(\"For\", i,\"cluster:\")\n",
    "        print(\"Max =\",c, \"with\", dum.keys()[a])\n",
    "        print(\"Min =\",d, \"with\", dum.keys()[b],\"\\n\")\n",
    "    \n",
    "    #plot\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        plt.bar(dum.keys(), w[i])\n",
    "        plt.title(i)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# In[7]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import compare\n",
    "compare(t_vector,n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Calculating persistence probablilities, transition probablilities, dwell times for each subject\n",
    "-------------------------------------------------------------------------\n",
    "\n",
    "We calculated several measures using brain states labels, to to better describe brain states dynamics. \n",
    "For each subject, session, and task we calculated state's: \n",
    "\n",
    "- **dwell times** - percentage of timepoints in each run classified as specific state\n",
    "- **transition probability** - probability of the transition from state $i$ to state $j$ given the current state $i$ divided by the sum of occurencies of $i$, resulting in $S\\times S$ probability matrix $P_{ij}$, where S is equal to number of examined states.\n",
    "- **persistence probability** - probability of the remaining in the same state. Diagonal elements of $P_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transition probabilities\n",
    "\n",
    "from nilearn import plotting\n",
    "import functions \n",
    "\n",
    "plotting.plot_matrix(functions.multiple_transition(n_clusters,t_rest).mean(axis=0), title = \"rest\")\n",
    "plotting.plot_matrix(functions.multiple_transition(n_clusters,t_nback).mean(axis=0), title = \"nback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Groups/sessions comparison\n",
    "-------------------------------------------------------------------------\n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

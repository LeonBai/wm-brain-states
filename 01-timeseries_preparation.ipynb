{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timeseries preparation\n",
    "=========================\n",
    "\n",
    "Prior to running clustering the time-series into discrete brain stets, all timeseries were concatenated into large $N \\times P$ array containing $N$ observation and $P$ features. The length of $N$ was equal to 227040 as a result of concatenating 4 sessions of dual n-back data (340 time-points) and resting state data (305 time-points) of 44 subjects. The length of $P$ was equal 400 and represented the mean signal extracted from each brain areas of Schaefer et al. (2018) brain parcellation.\n",
    "\n",
    "By this procedure we ensured the correspondence of brain states labels across subjects, sessions and tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data reduction\n",
    "---------------------------\n",
    "\n",
    "Before running k-means clustering algorythm, subjects with high motion or missing data in at least one session were excluded from analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects to exclude due to motion or missing data: ['sub-13' 'sub-20' 'sub-21' 'sub-23' 'sub-44' 'sub-46' 'sub-47']\n",
      "Number of subjects included in analyses: 39\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Selecting subjects for analysis\n",
    "groups = pd.read_csv('data/behavioral/group_assignment.csv')\n",
    "\n",
    "dualnback_motion = ['sub-13', 'sub-21', 'sub-23'] # higly motion subjects in one of four sessions\n",
    "rest_motion = ['sub-21', 'sub-46', 'sub-47'] # higly motion subjects in one of four sessions / missing data(20-44)\n",
    "rest_missing = ['sub-20', 'sub-44']\n",
    "\n",
    "exclude = np.unique(dualnback_motion + rest_motion + rest_missing)\n",
    "print(f'Subjects to exclude due to motion or missing data: {exclude}')\n",
    "\n",
    "groups['included'] = ((groups.group == 'Experimental') | (groups.group == 'Control')) & ~groups['sub'].isin(exclude)\n",
    "groups_clean = groups[groups['included'].values].reset_index()\n",
    "groups_clean.to_csv(\"./data/behavioral/groups_clean_dualnback_rest.csv\", index=False)\n",
    "\n",
    "n_sub = groups.included.values.sum()\n",
    "print(f'Number of subjects included in analyses: {n_sub}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Loading time-series\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dualnback data shape: (39, 4, 340, 400)\n",
      "Original rest data shape: (39, 4, 305, 400)\n"
     ]
    }
   ],
   "source": [
    "# Loading time-series data\n",
    "\n",
    "parcellation = \"schaefer\"\n",
    "tasks = [\"dualnback\", \"rest\"]\n",
    "n_roi = 400\n",
    "\n",
    "ts_dualnback_raw = np.load(\"timeseries_schaefer400_dualnback.npy\")\n",
    "ts_rest_raw = np.load(\"timeseries_schaefer400_rest.npy\")\n",
    "\n",
    "ts_dualnback = ts_dualnback_raw[groups['included'].values]\n",
    "ts_rest = ts_rest_raw[groups['included'].values]\n",
    "\n",
    "print(f'Original dualnback data shape: {ts_dualnback.shape}')\n",
    "print(f'Original rest data shape: {ts_rest.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Concatenating time-series\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dualnback timeseries: (53040, 400)\n",
      "Shape of rest timeseries: (47580, 400)\n",
      "Shape of all timeseries: (100620, 400)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating time-series\n",
    "n_ses = ts_dualnback.shape[1]\n",
    "n_rois = ts_dualnback.shape[3]\n",
    "\n",
    "cts_dualnback = ts_dualnback.reshape(n_sub*n_ses*ts_dualnback.shape[2], n_rois)     #all 46 subcjects in one vector\n",
    "cts_rest = ts_rest.reshape(n_sub*n_ses*ts_rest.shape[2], n_rois)\n",
    "\n",
    "# Concatenating task and rest\n",
    "cts_all = np.zeros((cts_dualnback.shape[0] + cts_rest.shape[0] , n_rois))\n",
    "cts_all[0:cts_dualnback.shape[0],:] = cts_dualnback \n",
    "cts_all[cts_dualnback.shape[0]:, :] = cts_rest\n",
    "\n",
    "np.save(\"./data/neuroimaging/timeseries_concat_all_schaefer400.npy\", cts_all)\n",
    "\n",
    "print(f\"Shape of dualnback timeseries: {cts_dualnback.shape}\")\n",
    "print(f\"Shape of rest timeseries: {cts_rest.shape}\")\n",
    "print(f\"Shape of all timeseries: {cts_all.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
